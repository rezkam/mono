// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: copyfrom.go

package sqlcgen

import (
	"context"
)

// iteratorForBatchCreateTodoItems implements pgx.CopyFromSource.
type iteratorForBatchCreateTodoItems struct {
	rows                 []BatchCreateTodoItemsParams
	skippedFirstNextCall bool
}

func (r *iteratorForBatchCreateTodoItems) Next() bool {
	if len(r.rows) == 0 {
		return false
	}
	if !r.skippedFirstNextCall {
		r.skippedFirstNextCall = true
		return true
	}
	r.rows = r.rows[1:]
	return len(r.rows) > 0
}

func (r iteratorForBatchCreateTodoItems) Values() ([]interface{}, error) {
	return []interface{}{
		r.rows[0].ID,
		r.rows[0].ListID,
		r.rows[0].Title,
		r.rows[0].Status,
		r.rows[0].Priority,
		r.rows[0].EstimatedDuration,
		r.rows[0].ActualDuration,
		r.rows[0].CreateTime,
		r.rows[0].UpdatedAt,
		r.rows[0].DueTime,
		r.rows[0].Tags,
		r.rows[0].RecurringTemplateID,
		r.rows[0].InstanceDate,
		r.rows[0].Timezone,
		r.rows[0].Version,
	}, nil
}

func (r iteratorForBatchCreateTodoItems) Err() error {
	return nil
}

// Bulk insert using PostgreSQL's COPY protocol.
// This bypasses:
//   - Query parsing per row
//   - Planner overhead per row
//   - Network round trips per row
//
// Result: ~10x performance for batch operations (30-90 items â†’ single operation).
func (q *Queries) BatchCreateTodoItems(ctx context.Context, arg []BatchCreateTodoItemsParams) (int64, error) {
	return q.db.CopyFrom(ctx, []string{"todo_items"}, []string{"id", "list_id", "title", "status", "priority", "estimated_duration", "actual_duration", "create_time", "updated_at", "due_time", "tags", "recurring_template_id", "instance_date", "timezone", "version"}, &iteratorForBatchCreateTodoItems{rows: arg})
}
